{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a7ca5c",
   "metadata": {},
   "source": [
    "# TPP Machine Learning Models\n",
    "\n",
    "Machine learning approaches for predicting and detecting Thyrotoxic Periodic Paralysis episodes.\n",
    "\n",
    "**Contents:**\n",
    "1. Feature engineering\n",
    "2. Classification models (episode vs normal)\n",
    "3. Regression models (heart rate prediction)\n",
    "4. Time-series forecasting\n",
    "5. Model evaluation and comparison\n",
    "6. Real-time prediction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027caa2",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "import json\n",
    "\n",
    "with open('../sample-data/heart-rate-sample.json', 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "df_json = pd.DataFrame(data_json)\n",
    "\n",
    "with open('../sample-data/night-monitoring.json', 'r') as f:\n",
    "    night_data = json.load(f)\n",
    "df_night = pd.DataFrame(night_data)\n",
    "\n",
    "df_csv = pd.read_csv('../sample-data/heart-rate-sample.csv')\n",
    "\n",
    "# Combine all data\n",
    "df = pd.concat([df_csv, df_json, df_night], ignore_index=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} total records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79f32d",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create additional features from raw data to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Rolling statistics (window=3 for small dataset)\n",
    "df['hr_rolling_mean'] = df['heartRate'].rolling(window=3, min_periods=1).mean()\n",
    "df['hr_rolling_std'] = df['heartRate'].rolling(window=3, min_periods=1).std().fillna(0)\n",
    "df['hrv_rolling_mean'] = df['hrv'].rolling(window=3, min_periods=1).mean()\n",
    "df['hrv_rolling_std'] = df['hrv'].rolling(window=3, min_periods=1).std().fillna(0)\n",
    "\n",
    "# Rate of change\n",
    "df['hr_change'] = df['heartRate'].diff().fillna(0)\n",
    "df['hrv_change'] = df['hrv'].diff().fillna(0)\n",
    "df['hr_change_abs'] = df['hr_change'].abs()\n",
    "\n",
    "# HR/HRV ratio\n",
    "df['hr_hrv_ratio'] = df['heartRate'] / (df['hrv'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# Encode activity as numeric\n",
    "le = LabelEncoder()\n",
    "df['activity_encoded'] = le.fit_transform(df['activity'])\n",
    "\n",
    "# Create binary target: low HR (potential episode indicator)\n",
    "# Typically TPP episodes show low heart rate\n",
    "df['low_hr_episode'] = (df['heartRate'] < 60).astype(int)\n",
    "\n",
    "print(\"âœ“ Feature engineering complete\")\n",
    "print(f\"Total features: {len(df.columns)}\")\n",
    "print(f\"\\nNew columns added: {[col for col in df.columns if col not in ['timestamp', 'heartRate', 'hrv', 'activity', 'device']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34321d6e",
   "metadata": {},
   "source": [
    "## 3. Classification: Episode Detection\n",
    "\n",
    "Build classification models to detect potential TPP episodes based on low heart rate patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for classification\n",
    "feature_cols = ['hrv', 'hour', 'day_of_week', 'is_night', 'is_weekend',\n",
    "                'hr_rolling_mean', 'hr_rolling_std', 'hrv_rolling_mean', 'hrv_rolling_std',\n",
    "                'hr_change', 'hrv_change', 'hr_change_abs', 'hr_hrv_ratio', 'activity_encoded']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['low_hr_episode']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Class distribution (train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Class distribution (test): {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fec27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple classification models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"  Precision: {precision:.3f}\")\n",
    "    print(f\"  Recall:    {recall:.3f}\")\n",
    "    print(f\"  F1 Score:  {f1:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results.keys()],\n",
    "    'Precision': [results[m]['precision'] for m in results.keys()],\n",
    "    'Recall': [results[m]['recall'] for m in results.keys()],\n",
    "    'F1 Score': [results[m]['f1'] for m in results.keys()]\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot of all metrics\n",
    "results_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1 Score']].plot(\n",
    "    kind='bar', ax=axes[0], rot=45\n",
    ")\n",
    "axes[0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_ylim(0, 1.0)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Best model confusion matrix\n",
    "best_model_name = results_df.loc[results_df['F1 Score'].idxmax(), 'Model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
    "axes[1].set_title(f'Confusion Matrix: {best_model_name}', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ† Best model: {best_model_name} (F1 Score: {results[best_model_name]['f1']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7d832",
   "metadata": {},
   "source": [
    "## 4. Regression: Heart Rate Prediction\n",
    "\n",
    "Build regression models to predict heart rate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for regression (predicting heart rate)\n",
    "regression_features = ['hrv', 'hour', 'day_of_week', 'is_night', 'is_weekend',\n",
    "                       'hrv_rolling_mean', 'hrv_rolling_std', 'hrv_change', 'activity_encoded']\n",
    "\n",
    "X_reg = df[regression_features]\n",
    "y_reg = df['heartRate']\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# Train multiple regression models\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_reg_scaled, y_train_reg)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_reg = model.predict(X_test_reg_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "    \n",
    "    regression_results[name] = {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred_reg\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE: {rmse:.2f} bpm\")\n",
    "    print(f\"  MAE:  {mae:.2f} bpm\")\n",
    "    print(f\"  RÂ²:   {r2:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad86995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Model comparison\n",
    "reg_comparison = pd.DataFrame({\n",
    "    'Model': list(regression_results.keys()),\n",
    "    'RMSE': [regression_results[m]['rmse'] for m in regression_results.keys()],\n",
    "    'MAE': [regression_results[m]['mae'] for m in regression_results.keys()],\n",
    "    'RÂ²': [regression_results[m]['r2'] for m in regression_results.keys()]\n",
    "})\n",
    "\n",
    "reg_comparison.set_index('Model')[['RMSE', 'MAE']].plot(kind='bar', ax=axes[0], rot=45)\n",
    "axes[0].set_title('Regression Model Comparison (Error Metrics)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Error (bpm)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Best model predictions vs actual\n",
    "best_reg_model = reg_comparison.loc[reg_comparison['RMSE'].idxmin(), 'Model']\n",
    "best_reg_preds = regression_results[best_reg_model]['predictions']\n",
    "\n",
    "axes[1].scatter(y_test_reg, best_reg_preds, alpha=0.6, s=50)\n",
    "axes[1].plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Heart Rate (bpm)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Heart Rate (bpm)', fontsize=12)\n",
    "axes[1].set_title(f'Predictions vs Actual: {best_reg_model}', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ† Best regression model: {best_reg_model} (RMSE: {regression_results[best_reg_model]['rmse']:.2f} bpm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fb3f4",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis\n",
    "\n",
    "Identify which features are most important for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest classifier\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance for Episode Detection', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
